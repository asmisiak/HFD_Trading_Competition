{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e440d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quantstats as qs\n",
    "from fun.position_VB import positionVB\n",
    "\n",
    "quarters = ['2023_Q1', '2023_Q3', '2023_Q4',\n",
    "            '2024_Q2', '2024_Q4',\n",
    "            '2025_Q1', '2025_Q2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48337f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing quarter: 2023_Q1\n",
      "Processing quarter: 2023_Q3\n",
      "Processing quarter: 2023_Q4\n",
      "Processing quarter: 2024_Q2\n",
      "Processing quarter: 2024_Q4\n",
      "Processing quarter: 2025_Q1\n",
      "Processing quarter: 2025_Q2\n"
     ]
    }
   ],
   "source": [
    "def mySR(x, scale):\n",
    "    return np.sqrt(scale) * np.nanmean(x) / np.nanstd(x)\n",
    "\n",
    "# create an empty DataFrame to store summary for all quarters\n",
    "summary_data2_all_quarters = pd.DataFrame()\n",
    "\n",
    "for quarter in quarters:\n",
    "\n",
    "    print(f'Processing quarter: {quarter}')\n",
    "\n",
    "    data2 = pd.read_parquet(f'data/data2_{quarter}.parquet')\n",
    "\n",
    "    # Lets set the datetime index\n",
    "    data2.set_index('datetime', inplace = True)\n",
    "\n",
    "\n",
    "    # assumption\n",
    "    # let's create an object named \"pos_flat\" \n",
    "    # = 1 if position has to be flat (= 0) - we do not trade\n",
    "    # = 0 otherwise\n",
    "\n",
    "    # let's fill it first with zeros\n",
    "    pos_flat = np.zeros(len(data2))\n",
    "\n",
    "    # \n",
    "    breaks = (data2.index.time >= pd.to_datetime(\"16:41\").time()) & \\\n",
    "          (data2.index.time <= pd.to_datetime(\"18:10\").time())\n",
    "    \n",
    "    pos_flat[breaks] = 1\n",
    "\n",
    "    dweek_ = data2.index.dayofweek + 1\n",
    "    time_ = data2.index.time\n",
    "    pos_flat[((dweek_ == 5) & (time_ > pd.to_datetime('17:00').time())) |      # end of Friday\n",
    "          (dweek_ == 6) |                                                  # whole Saturday (just in case)\n",
    "          ((dweek_ == 7) & (time_ <= pd.to_datetime('18:00').time()))] = 1\n",
    "                                                               # beginning of Sunday\n",
    "    # apply the strategy\n",
    "    ##############################################################\n",
    "    \n",
    "    # We calculate the appropriate EMA\n",
    "    signalEMA_values = data2['XAG'].ewm(span = 30).mean().to_numpy()\n",
    "    slowEMA_values = data2['XAG'].ewm(span = 240).mean().to_numpy()\n",
    "                                \n",
    "    # We calculate the standard deviation\n",
    "    volat_sd_values = data2['XAG'].rolling(window = 60).std().to_numpy()\n",
    "\n",
    "    # Insert NaNs wherever the original price is missing\n",
    "    signalEMA_values[data2['XAG'].isna()] = np.nan\n",
    "    slowEMA_values[data2['XAG'].isna()] = np.nan \n",
    "    volat_sd_values[data2['XAG'].isna()] = np.nan \n",
    "\n",
    "    # Calculate position for momentum strategy\n",
    "    pos_mom = positionVB(signal = signalEMA_values, \n",
    "                        lower = slowEMA_values - 1 * volat_sd_values,\n",
    "                        upper = slowEMA_values + 1 * volat_sd_values,\n",
    "                        pos_flat = pos_flat,\n",
    "                        strategy = \"mom\")\n",
    "    pos_mr = -pos_mom\n",
    "    pos_mr[pos_flat == 1] = 0\n",
    "    pos_mom[pos_flat == 1] = 0\n",
    "\n",
    "    # Calculate gross pnl  <------ pierwsza poprawka\n",
    "    #pnl_gross_mr = np.where(np.isnan(pos_mom * data2['XAG'].diff()), 0, pos_mom * data2['XAG'].diff() * 5000) \n",
    "    pnl_gross_mr = np.where(np.isnan(pos_mr * data2['XAG'].diff()), 0, pos_mr * data2['XAG'].diff() * 5000) \n",
    "    pnl_gross_mr_pct = pnl_gross_mr / data2[\"XAG\"].shift(1)\n",
    "\n",
    "    # Add stop loss condition\n",
    "                    # Calculate cumulative PnL for each day and apply stop loss\n",
    "    pnl_gross_mr_series = pd.Series(pnl_gross_mr, index=data2.index)\n",
    "                    \n",
    "    # Define stop loss threshold (e.g., -1000 per day)\n",
    "    stop_loss_threshold = -1000\n",
    "                    \n",
    "    # Calculate cumulative daily PnL\n",
    "    daily_cumul_pnl_mr = pnl_gross_mr_series.groupby(data2.index.date).cumsum()\n",
    "                    \n",
    "    # Create stop loss mask (stop trading for rest of day if threshold hit)\n",
    "    stop_loss_triggered_mr = (daily_cumul_pnl_mr <= stop_loss_threshold).groupby(data2.index.date).cummax()\n",
    "                    \n",
    "    # Apply stop loss by setting position to 0 after trigger <------- druga poprawka\n",
    "    #pos_mr_sl = pos_mom.copy()\n",
    "    pos_mr_sl = pos_mr.copy()\n",
    "    pos_mr_sl[stop_loss_triggered_mr] = 0\n",
    "\n",
    "                    \n",
    "    # Recalculate PnL with stop loss\n",
    "    pnl_gross_mr = np.where(np.isnan(pos_mr_sl * data2['XAG'].diff()), 0, pos_mr_sl * data2['XAG'].diff() * 5000)\n",
    "    capital = np.abs(pos_mr_sl) * data2[\"XAG\"] * 5000 # <----- czwarta poprawka\n",
    "    pnl_gross_mr_pct = pnl_gross_mr / capital.replace(0, np.nan)\n",
    "    #pnl_gross_mr_pct = pnl_gross_mr / data2[\"XAG\"].shift(1)\n",
    "    # Calculate number of transactions\n",
    "    #ntrans = np.abs(np.diff(pos_mom, prepend = 0)) <------ trzecia poprawka\n",
    "    ntrans = np.abs(np.diff(pos_mr_sl, prepend = 0))\n",
    "\n",
    "    # Calculate net pnl\n",
    "    pnl_net_mr = pnl_gross_mr - ntrans * 10  # cost $10 per transaction on E6\n",
    "    pnl_net_mr_pct = pnl_net_mr / capital.replace(0, np.nan)\n",
    "    #pnl_net_mr_pct = pnl_net_mr / data2[\"XAG\"].shift(1) <----- piÄ…ta poprawka \n",
    "\n",
    "    # Aggregate to daily data\n",
    "    pnl_gross_mr = pd.Series(pnl_gross_mr)\n",
    "    pnl_gross_mr.index = data2['XAG'].index.time\n",
    "    pnl_gross_mr_d = pnl_gross_mr.groupby(data2['XAG'].index.date).sum()\n",
    "    pnl_gross_mr_pct_d = pnl_gross_mr_pct.groupby(data2.index.date).sum()\n",
    "\n",
    "    pnl_net_mr = pd.Series(pnl_net_mr)\n",
    "    pnl_net_mr.index = data2['XAG'].index.time\n",
    "    pnl_net_mr_d = pnl_net_mr.groupby(data2['XAG'].index.date).sum()\n",
    "    pnl_net_mr_pct_d = pnl_net_mr_pct.groupby(data2.index.date).sum()\n",
    "\n",
    "    ntrans = pd.Series(ntrans)\n",
    "    ntrans.index = data2['XAG'].index.time\n",
    "    ntrans_d = ntrans.groupby(data2['XAG'].index.date).sum()\n",
    "\n",
    "    gross_SR_mr = mySR(pnl_gross_mr_d, scale=252)\n",
    "    net_SR_mr = mySR(pnl_net_mr_d, scale=252)\n",
    "    gross_PnL_mr = pnl_gross_mr_d.sum()\n",
    "    net_PnL_mr = pnl_net_mr_d.sum()\n",
    "    gross_CR_mr = qs.stats.calmar(pnl_gross_mr_pct_d.dropna()).round(4)\n",
    "    net_CR_mr = qs.stats.calmar(pnl_net_mr_pct_d.dropna()).round(4)\n",
    "    \n",
    "    av_daily_ntrans = ntrans_d.mean()\n",
    "    stat = (net_SR_mr - 0.5) * np.maximum(0, np.log(np.abs(net_PnL_mr/1000)))\n",
    "\n",
    "\n",
    "                    # Collect the necessary results into one object\n",
    "    summary = pd.DataFrame({'quarter': quarter,\n",
    "                            'gross_SR': gross_SR_mr,\n",
    "                            'net_SR': net_SR_mr,\n",
    "                            'gross_PnL': gross_PnL_mr,\n",
    "                            'net_PnL': net_PnL_mr,\n",
    "                            'gross_CR': gross_CR_mr,\n",
    "                            'net_CR': net_CR_mr,\n",
    "                            'av_daily_ntrans': av_daily_ntrans,\n",
    "                            'stat': stat\n",
    "                        }, index=[0])\n",
    "\n",
    "                \n",
    "              \n",
    "    # Append results to the summary\n",
    "    summary_data2_all_quarters = pd.concat([summary_data2_all_quarters, summary], ignore_index=True)\n",
    "\n",
    "    # plot of cumulative gros and net returns\n",
    "    # and save it as a png file\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.cumsum(pnl_gross_mr_d.fillna(0)), label = 'Gross PnL', color='blue')\n",
    "    plt.plot(np.cumsum(pnl_net_mr_d.fillna(0)), label = 'Net PnL', color='red')\n",
    "    plt.title('Cumulative Gross and Net PnL (' + quarter + ')')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x')\n",
    "\n",
    "    plt.savefig(f\"data2_{quarter}.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # remove ALL created objects to free memory\n",
    "    # and prevent potential bugs in the next iteration\n",
    "    del data2, pos_flat, signalEMA_values, slowEMA_values, volat_sd_values\n",
    "    del pos_mr, pnl_gross_mr, pnl_gross_mr_pct, pnl_net_mr, pnl_net_mr_pct\n",
    "    del ntrans, pnl_gross_mr_d, pnl_gross_mr_pct_d, pnl_net_mr_d, pnl_net_mr_pct_d\n",
    "    del ntrans_d, summary\n",
    "\n",
    "# save the summary for all quarters to a csv file\n",
    "summary_data2_all_quarters.to_csv('summary_data2_all_quarters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6bd0f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>gross_SR</th>\n",
       "      <th>net_SR</th>\n",
       "      <th>gross_PnL</th>\n",
       "      <th>net_PnL</th>\n",
       "      <th>gross_CR</th>\n",
       "      <th>net_CR</th>\n",
       "      <th>av_daily_ntrans</th>\n",
       "      <th>stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023_Q1</td>\n",
       "      <td>2.756026</td>\n",
       "      <td>2.478230</td>\n",
       "      <td>18290.0</td>\n",
       "      <td>16270.0</td>\n",
       "      <td>13.5888</td>\n",
       "      <td>11.6850</td>\n",
       "      <td>2.589744</td>\n",
       "      <td>5.517921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023_Q3</td>\n",
       "      <td>-0.126403</td>\n",
       "      <td>-0.465932</td>\n",
       "      <td>-655.0</td>\n",
       "      <td>-2395.0</td>\n",
       "      <td>-0.3362</td>\n",
       "      <td>-0.6670</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>-0.843629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023_Q4</td>\n",
       "      <td>2.409315</td>\n",
       "      <td>2.090316</td>\n",
       "      <td>13515.0</td>\n",
       "      <td>11635.0</td>\n",
       "      <td>5.0918</td>\n",
       "      <td>4.4934</td>\n",
       "      <td>2.410256</td>\n",
       "      <td>3.902664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024_Q2</td>\n",
       "      <td>3.795837</td>\n",
       "      <td>3.591157</td>\n",
       "      <td>32820.0</td>\n",
       "      <td>30850.0</td>\n",
       "      <td>35.1974</td>\n",
       "      <td>32.6700</td>\n",
       "      <td>2.525641</td>\n",
       "      <td>10.599999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024_Q4</td>\n",
       "      <td>3.146175</td>\n",
       "      <td>2.917699</td>\n",
       "      <td>22325.0</td>\n",
       "      <td>20525.0</td>\n",
       "      <td>16.9609</td>\n",
       "      <td>15.5467</td>\n",
       "      <td>2.278481</td>\n",
       "      <td>7.305426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025_Q1</td>\n",
       "      <td>-1.062477</td>\n",
       "      <td>-1.372548</td>\n",
       "      <td>-5900.0</td>\n",
       "      <td>-7560.0</td>\n",
       "      <td>-1.6954</td>\n",
       "      <td>-1.8582</td>\n",
       "      <td>2.155844</td>\n",
       "      <td>-3.787924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025_Q2</td>\n",
       "      <td>1.421646</td>\n",
       "      <td>1.176341</td>\n",
       "      <td>9855.0</td>\n",
       "      <td>8095.0</td>\n",
       "      <td>3.2606</td>\n",
       "      <td>2.7796</td>\n",
       "      <td>2.256410</td>\n",
       "      <td>1.414395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter  gross_SR    net_SR  gross_PnL  net_PnL  gross_CR   net_CR  \\\n",
       "0  2023_Q1  2.756026  2.478230    18290.0  16270.0   13.5888  11.6850   \n",
       "1  2023_Q3 -0.126403 -0.465932     -655.0  -2395.0   -0.3362  -0.6670   \n",
       "2  2023_Q4  2.409315  2.090316    13515.0  11635.0    5.0918   4.4934   \n",
       "3  2024_Q2  3.795837  3.591157    32820.0  30850.0   35.1974  32.6700   \n",
       "4  2024_Q4  3.146175  2.917699    22325.0  20525.0   16.9609  15.5467   \n",
       "5  2025_Q1 -1.062477 -1.372548    -5900.0  -7560.0   -1.6954  -1.8582   \n",
       "6  2025_Q2  1.421646  1.176341     9855.0   8095.0    3.2606   2.7796   \n",
       "\n",
       "   av_daily_ntrans       stat  \n",
       "0         2.589744   5.517921  \n",
       "1         2.230769  -0.843629  \n",
       "2         2.410256   3.902664  \n",
       "3         2.525641  10.599999  \n",
       "4         2.278481   7.305426  \n",
       "5         2.155844  -3.787924  \n",
       "6         2.256410   1.414395  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_data2_all_quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54479e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
